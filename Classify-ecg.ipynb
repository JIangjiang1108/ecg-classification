{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from wfdb import io, plot\n",
    "import wfdb\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout, Input\n",
    "from keras.layers import CuDNNLSTM as LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comments_to_dict(comments):\n",
    "    key_value_pairs = [comment.split(':') for comment in comments]\n",
    "    return {pair[0]: pair[1] for pair in key_value_pairs}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO save this locally\n",
    "db = 'ptbdb'\n",
    "record_names = io.get_record_list(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_to_row(record, patient_id):\n",
    "    row = {}\n",
    "    row['patient'] = patient_id\n",
    "    row['name'] = record.record_name\n",
    "    row['label'] = comments_to_dict(record.comments)['Reason for admission'][1:]\n",
    "    row['signals'] = record.p_signal\n",
    "    row['signal_length'] = record.sig_len\n",
    "    channels = record.sig_name\n",
    "    signals = record.p_signal.transpose()\n",
    "    \n",
    "    row['channels'] = channels\n",
    "    \n",
    "    for channel, signal in zip(channels, signals):\n",
    "        row[channel] = signal\n",
    "        \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'record_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bac5dc6f34bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrecords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mrecord_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mrecord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomments_to_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Reason for admission'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mrecords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord_to_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'record_names' is not defined"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for record_name in tqdm(record_names):\n",
    "    record = io.rdrecord(record_name=os.path.join('data', record_name))\n",
    "    label = comments_to_dict(record.comments)['Reason for admission'][1:]\n",
    "    records.append(record_to_row(record, record_name.split('/')[0]))\n",
    "    \n",
    "channels = record.sig_name\n",
    "df_records = pd.DataFrame(records)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_records' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-97fbbc56dd36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_records\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_records\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_records' is not defined"
     ]
    }
   ],
   "source": [
    "labels = df_records['label'].unique()\n",
    "df_records['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_labels = ['Healthy control', 'Myocardial infarction', 'Bundle branch block', 'Dysrhythmia', 'Hypertrophy']\n",
    "df_selected = df_records.loc[df_records['label'].isin(selected_labels)]\n",
    "label_map = {label: value for label, value in zip(selected_labels, range(len(selected_labels)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patients = []\n",
    "train_patients = []\n",
    "test_size = 0.33\n",
    "channels\n",
    "for label in selected_labels:\n",
    "    df_selected = df_records.loc[df_records['label'] == label]\n",
    "    patients = df_selected['patient'].unique()\n",
    "    n_test = math.ceil(len(patients)*test_size)\n",
    "    test_patients+=list(np.random.choice(patients, n_test, replace=False))\n",
    "    train_patients+=list(patients[np.isin(patients, test_patients, invert=True)])\n",
    "#df_selected['patient'].sample(len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_set(df_data, channels, label_map, window_size=2048):\n",
    "    n_windows = 0\n",
    "    \n",
    "    for _, record in tqdm(df_data.iterrows()):\n",
    "        n_windows+= record['signals'].shape[0]//window_size\n",
    "\n",
    "    dataX = np.zeros((n_windows, len(channels), window_size))\n",
    "    dataY = np.zeros((n_windows, len(label_map)))\n",
    "\n",
    "    nth_window = 0\n",
    "    for i, (_, record) in enumerate(tqdm(df_data.iterrows())):\n",
    "        # Set class\n",
    "        \n",
    "        data = record['signals'].transpose()\n",
    "        n_rows = data.shape[-1]\n",
    "        n_windows = n_rows//window_size\n",
    "        dataX[nth_window:nth_window+n_windows] = np.array([data[:,i*window_size:(i+1)*window_size] for i in range(n_windows)])\n",
    "        dataY[nth_window:nth_window+n_windows][:, label_map[record.label]] = 1\n",
    "        nth_window+=n_windows\n",
    "        \n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f42a91e8cc04c1392df260a641620b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9805c0ca6e94a9c9b5227bc97bcee82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc1a84cf24e4dff96167c71b22eb2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34b7984a62448dbb360f5d85ee293fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_patient_records = df_records.set_index('patient')\n",
    "df_train_patients = df_patient_records.loc[train_patients]\n",
    "df_test_patients = df_patient_records.loc[train_patients]\n",
    "trainX, trainY = make_set(df_train_patients, channels, label_map)\n",
    "testX, testY = make_set(df_test_patients, channels, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc4241ee94b4606ac3b2ed20d9e0b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "window_size=2048\n",
    "n_windows = 0\n",
    "nth_window = 0\n",
    "for _, record in tqdm(df_test_patients.iterrows()):\n",
    "    n_windows+= record['signals'].shape[0]//window_size\n",
    "\n",
    "dataX = np.zeros((n_windows, len(channels), window_size))\n",
    "dataY = np.zeros((n_windows, len(label_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_enc_dec(input_shape, output_dim, stateful=False, dropout=0.2):\n",
    "    print(\"model dim: \", input_shape, output_dim)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, return_sequences=True, input_shape=input_shape, batch_size=None, stateful=stateful))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(128, return_sequences=True), stateful=stateful)\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(64), return_sequences=True, stateful=stateful)\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(128), return_sequences=True, stageful=stateful)\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(256), return_sequences=True, stageful=stateful)\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(input_shape[-1]))\n",
    "    #model.add(Dense(output_dim, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, output_dim):\n",
    "    print(\"model dim: \", input_shape, output_dim)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, return_sequences=True, input_shape=input_shape, batch_size=None))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model dim:  (15, 2048) 5\n",
      "Epoch 1/50\n",
      "17286/17286 [==============================] - ETA: 1:11 - loss: 1.642 - ETA: 53s - loss: 1.458 - ETA: 45s - loss: 1.30 - ETA: 40s - loss: 1.19 - ETA: 34s - loss: 1.13 - ETA: 30s - loss: 1.08 - ETA: 26s - loss: 1.05 - ETA: 24s - loss: 1.02 - ETA: 21s - loss: 0.99 - ETA: 19s - loss: 0.97 - ETA: 18s - loss: 0.95 - ETA: 16s - loss: 0.95 - ETA: 15s - loss: 0.93 - ETA: 14s - loss: 0.93 - ETA: 13s - loss: 0.92 - ETA: 12s - loss: 0.91 - ETA: 11s - loss: 0.91 - ETA: 10s - loss: 0.90 - ETA: 10s - loss: 0.89 - ETA: 9s - loss: 0.8888 - ETA: 8s - loss: 0.886 - ETA: 7s - loss: 0.881 - ETA: 7s - loss: 0.876 - ETA: 6s - loss: 0.870 - ETA: 6s - loss: 0.866 - ETA: 5s - loss: 0.859 - ETA: 4s - loss: 0.858 - ETA: 4s - loss: 0.853 - ETA: 3s - loss: 0.851 - ETA: 2s - loss: 0.848 - ETA: 2s - loss: 0.846 - ETA: 1s - loss: 0.843 - ETA: 0s - loss: 0.842 - 27s 2ms/step - loss: 0.8399\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.83993, saving model to models\\weights-improvement-01-bigger.hdf5\n",
      "Epoch 2/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.808 - ETA: 4s - loss: 0.749 - ETA: 4s - loss: 0.773 - ETA: 4s - loss: 0.766 - ETA: 4s - loss: 0.772 - ETA: 4s - loss: 0.775 - ETA: 4s - loss: 0.775 - ETA: 3s - loss: 0.778 - ETA: 3s - loss: 0.770 - ETA: 3s - loss: 0.768 - ETA: 3s - loss: 0.768 - ETA: 3s - loss: 0.767 - ETA: 3s - loss: 0.768 - ETA: 3s - loss: 0.768 - ETA: 2s - loss: 0.763 - ETA: 2s - loss: 0.762 - ETA: 2s - loss: 0.758 - ETA: 2s - loss: 0.759 - ETA: 2s - loss: 0.753 - ETA: 2s - loss: 0.753 - ETA: 1s - loss: 0.751 - ETA: 1s - loss: 0.750 - ETA: 1s - loss: 0.754 - ETA: 1s - loss: 0.754 - ETA: 1s - loss: 0.754 - ETA: 1s - loss: 0.756 - ETA: 1s - loss: 0.759 - ETA: 0s - loss: 0.759 - ETA: 0s - loss: 0.757 - ETA: 0s - loss: 0.755 - ETA: 0s - loss: 0.753 - ETA: 0s - loss: 0.755 - ETA: 0s - loss: 0.754 - 5s 305us/step - loss: 0.7545\n",
      "\n",
      "Epoch 00002: loss improved from 0.83993 to 0.75453, saving model to models\\weights-improvement-02-bigger.hdf5\n",
      "Epoch 3/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.738 - ETA: 4s - loss: 0.706 - ETA: 4s - loss: 0.706 - ETA: 4s - loss: 0.725 - ETA: 4s - loss: 0.742 - ETA: 4s - loss: 0.735 - ETA: 3s - loss: 0.733 - ETA: 3s - loss: 0.734 - ETA: 3s - loss: 0.735 - ETA: 3s - loss: 0.732 - ETA: 3s - loss: 0.720 - ETA: 3s - loss: 0.715 - ETA: 3s - loss: 0.706 - ETA: 2s - loss: 0.701 - ETA: 2s - loss: 0.700 - ETA: 2s - loss: 0.695 - ETA: 2s - loss: 0.692 - ETA: 2s - loss: 0.691 - ETA: 2s - loss: 0.684 - ETA: 2s - loss: 0.683 - ETA: 1s - loss: 0.685 - ETA: 1s - loss: 0.685 - ETA: 1s - loss: 0.684 - ETA: 1s - loss: 0.682 - ETA: 1s - loss: 0.681 - ETA: 1s - loss: 0.681 - ETA: 0s - loss: 0.678 - ETA: 0s - loss: 0.674 - ETA: 0s - loss: 0.672 - ETA: 0s - loss: 0.668 - ETA: 0s - loss: 0.666 - ETA: 0s - loss: 0.667 - ETA: 0s - loss: 0.665 - 5s 288us/step - loss: 0.6644\n",
      "\n",
      "Epoch 00003: loss improved from 0.75453 to 0.66438, saving model to models\\weights-improvement-03-bigger.hdf5\n",
      "Epoch 4/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.569 - ETA: 4s - loss: 0.584 - ETA: 4s - loss: 0.579 - ETA: 4s - loss: 0.574 - ETA: 4s - loss: 0.586 - ETA: 4s - loss: 0.594 - ETA: 3s - loss: 0.588 - ETA: 3s - loss: 0.591 - ETA: 3s - loss: 0.587 - ETA: 3s - loss: 0.584 - ETA: 3s - loss: 0.583 - ETA: 3s - loss: 0.579 - ETA: 3s - loss: 0.573 - ETA: 2s - loss: 0.580 - ETA: 2s - loss: 0.587 - ETA: 2s - loss: 0.589 - ETA: 2s - loss: 0.585 - ETA: 2s - loss: 0.585 - ETA: 2s - loss: 0.588 - ETA: 2s - loss: 0.587 - ETA: 1s - loss: 0.584 - ETA: 1s - loss: 0.582 - ETA: 1s - loss: 0.578 - ETA: 1s - loss: 0.578 - ETA: 1s - loss: 0.576 - ETA: 1s - loss: 0.575 - ETA: 0s - loss: 0.573 - ETA: 0s - loss: 0.572 - ETA: 0s - loss: 0.573 - ETA: 0s - loss: 0.575 - ETA: 0s - loss: 0.576 - ETA: 0s - loss: 0.575 - ETA: 0s - loss: 0.573 - 5s 287us/step - loss: 0.5741\n",
      "\n",
      "Epoch 00004: loss improved from 0.66438 to 0.57413, saving model to models\\weights-improvement-04-bigger.hdf5\n",
      "Epoch 5/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.478 - ETA: 4s - loss: 0.484 - ETA: 4s - loss: 0.484 - ETA: 4s - loss: 0.507 - ETA: 4s - loss: 0.503 - ETA: 4s - loss: 0.494 - ETA: 3s - loss: 0.497 - ETA: 3s - loss: 0.504 - ETA: 3s - loss: 0.499 - ETA: 3s - loss: 0.501 - ETA: 3s - loss: 0.505 - ETA: 3s - loss: 0.501 - ETA: 3s - loss: 0.496 - ETA: 2s - loss: 0.498 - ETA: 2s - loss: 0.499 - ETA: 2s - loss: 0.498 - ETA: 2s - loss: 0.496 - ETA: 2s - loss: 0.496 - ETA: 2s - loss: 0.497 - ETA: 2s - loss: 0.494 - ETA: 1s - loss: 0.491 - ETA: 1s - loss: 0.493 - ETA: 1s - loss: 0.494 - ETA: 1s - loss: 0.493 - ETA: 1s - loss: 0.492 - ETA: 1s - loss: 0.491 - ETA: 0s - loss: 0.495 - ETA: 0s - loss: 0.493 - ETA: 0s - loss: 0.491 - ETA: 0s - loss: 0.490 - ETA: 0s - loss: 0.490 - ETA: 0s - loss: 0.490 - ETA: 0s - loss: 0.490 - 5s 287us/step - loss: 0.4897\n",
      "\n",
      "Epoch 00005: loss improved from 0.57413 to 0.48967, saving model to models\\weights-improvement-05-bigger.hdf5\n",
      "Epoch 6/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.439 - ETA: 4s - loss: 0.460 - ETA: 4s - loss: 0.443 - ETA: 4s - loss: 0.431 - ETA: 4s - loss: 0.424 - ETA: 4s - loss: 0.423 - ETA: 3s - loss: 0.425 - ETA: 3s - loss: 0.422 - ETA: 3s - loss: 0.422 - ETA: 3s - loss: 0.425 - ETA: 3s - loss: 0.422 - ETA: 3s - loss: 0.417 - ETA: 3s - loss: 0.413 - ETA: 3s - loss: 0.413 - ETA: 3s - loss: 0.412 - ETA: 2s - loss: 0.412 - ETA: 2s - loss: 0.413 - ETA: 2s - loss: 0.414 - ETA: 2s - loss: 0.414 - ETA: 2s - loss: 0.418 - ETA: 2s - loss: 0.417 - ETA: 1s - loss: 0.418 - ETA: 1s - loss: 0.418 - ETA: 1s - loss: 0.417 - ETA: 1s - loss: 0.418 - ETA: 1s - loss: 0.415 - ETA: 1s - loss: 0.415 - ETA: 0s - loss: 0.413 - ETA: 0s - loss: 0.415 - ETA: 0s - loss: 0.414 - ETA: 0s - loss: 0.414 - ETA: 0s - loss: 0.414 - ETA: 0s - loss: 0.412 - 5s 307us/step - loss: 0.4126\n",
      "\n",
      "Epoch 00006: loss improved from 0.48967 to 0.41255, saving model to models\\weights-improvement-06-bigger.hdf5\n",
      "Epoch 7/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.365 - ETA: 4s - loss: 0.363 - ETA: 4s - loss: 0.359 - ETA: 4s - loss: 0.351 - ETA: 4s - loss: 0.339 - ETA: 4s - loss: 0.342 - ETA: 3s - loss: 0.338 - ETA: 3s - loss: 0.337 - ETA: 3s - loss: 0.342 - ETA: 3s - loss: 0.346 - ETA: 3s - loss: 0.344 - ETA: 3s - loss: 0.343 - ETA: 3s - loss: 0.339 - ETA: 2s - loss: 0.338 - ETA: 2s - loss: 0.340 - ETA: 2s - loss: 0.337 - ETA: 2s - loss: 0.337 - ETA: 2s - loss: 0.335 - ETA: 2s - loss: 0.335 - ETA: 2s - loss: 0.334 - ETA: 1s - loss: 0.331 - ETA: 1s - loss: 0.332 - ETA: 1s - loss: 0.332 - ETA: 1s - loss: 0.333 - ETA: 1s - loss: 0.332 - ETA: 1s - loss: 0.333 - ETA: 0s - loss: 0.333 - ETA: 0s - loss: 0.333 - ETA: 0s - loss: 0.334 - ETA: 0s - loss: 0.334 - ETA: 0s - loss: 0.336 - ETA: 0s - loss: 0.337 - ETA: 0s - loss: 0.339 - 5s 286us/step - loss: 0.3369\n",
      "\n",
      "Epoch 00007: loss improved from 0.41255 to 0.33691, saving model to models\\weights-improvement-07-bigger.hdf5\n",
      "Epoch 8/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.321 - ETA: 4s - loss: 0.290 - ETA: 4s - loss: 0.298 - ETA: 4s - loss: 0.297 - ETA: 4s - loss: 0.300 - ETA: 4s - loss: 0.298 - ETA: 3s - loss: 0.293 - ETA: 3s - loss: 0.290 - ETA: 3s - loss: 0.285 - ETA: 3s - loss: 0.286 - ETA: 3s - loss: 0.286 - ETA: 3s - loss: 0.283 - ETA: 3s - loss: 0.286 - ETA: 2s - loss: 0.281 - ETA: 2s - loss: 0.279 - ETA: 2s - loss: 0.276 - ETA: 2s - loss: 0.274 - ETA: 2s - loss: 0.273 - ETA: 2s - loss: 0.275 - ETA: 2s - loss: 0.275 - ETA: 1s - loss: 0.273 - ETA: 1s - loss: 0.272 - ETA: 1s - loss: 0.271 - ETA: 1s - loss: 0.273 - ETA: 1s - loss: 0.273 - ETA: 1s - loss: 0.272 - ETA: 0s - loss: 0.273 - ETA: 0s - loss: 0.274 - ETA: 0s - loss: 0.274 - ETA: 0s - loss: 0.275 - ETA: 0s - loss: 0.274 - ETA: 0s - loss: 0.274 - ETA: 0s - loss: 0.273 - 5s 288us/step - loss: 0.2743\n",
      "\n",
      "Epoch 00008: loss improved from 0.33691 to 0.27434, saving model to models\\weights-improvement-08-bigger.hdf5\n",
      "Epoch 9/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.210 - ETA: 4s - loss: 0.226 - ETA: 4s - loss: 0.229 - ETA: 4s - loss: 0.234 - ETA: 4s - loss: 0.233 - ETA: 4s - loss: 0.232 - ETA: 3s - loss: 0.231 - ETA: 3s - loss: 0.229 - ETA: 3s - loss: 0.230 - ETA: 3s - loss: 0.230 - ETA: 3s - loss: 0.226 - ETA: 3s - loss: 0.229 - ETA: 3s - loss: 0.223 - ETA: 2s - loss: 0.222 - ETA: 2s - loss: 0.225 - ETA: 2s - loss: 0.222 - ETA: 2s - loss: 0.223 - ETA: 2s - loss: 0.224 - ETA: 2s - loss: 0.224 - ETA: 2s - loss: 0.224 - ETA: 1s - loss: 0.224 - ETA: 1s - loss: 0.223 - ETA: 1s - loss: 0.223 - ETA: 1s - loss: 0.224 - ETA: 1s - loss: 0.224 - ETA: 1s - loss: 0.224 - ETA: 1s - loss: 0.226 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.226 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.228 - ETA: 0s - loss: 0.227 - ETA: 0s - loss: 0.227 - 5s 291us/step - loss: 0.2306\n",
      "\n",
      "Epoch 00009: loss improved from 0.27434 to 0.23062, saving model to models\\weights-improvement-09-bigger.hdf5\n",
      "Epoch 10/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.174 - ETA: 4s - loss: 0.162 - ETA: 4s - loss: 0.164 - ETA: 4s - loss: 0.170 - ETA: 4s - loss: 0.171 - ETA: 4s - loss: 0.171 - ETA: 3s - loss: 0.171 - ETA: 3s - loss: 0.176 - ETA: 3s - loss: 0.175 - ETA: 3s - loss: 0.177 - ETA: 3s - loss: 0.181 - ETA: 3s - loss: 0.183 - ETA: 3s - loss: 0.185 - ETA: 2s - loss: 0.186 - ETA: 2s - loss: 0.188 - ETA: 2s - loss: 0.190 - ETA: 2s - loss: 0.190 - ETA: 2s - loss: 0.188 - ETA: 2s - loss: 0.187 - ETA: 2s - loss: 0.187 - ETA: 1s - loss: 0.186 - ETA: 1s - loss: 0.187 - ETA: 1s - loss: 0.185 - ETA: 1s - loss: 0.185 - ETA: 1s - loss: 0.184 - ETA: 1s - loss: 0.184 - ETA: 1s - loss: 0.184 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.184 - ETA: 0s - loss: 0.185 - 5s 290us/step - loss: 0.1841\n",
      "\n",
      "Epoch 00010: loss improved from 0.23062 to 0.18409, saving model to models\\weights-improvement-10-bigger.hdf5\n",
      "Epoch 11/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.161 - ETA: 4s - loss: 0.157 - ETA: 4s - loss: 0.159 - ETA: 4s - loss: 0.150 - ETA: 4s - loss: 0.141 - ETA: 4s - loss: 0.146 - ETA: 3s - loss: 0.142 - ETA: 3s - loss: 0.139 - ETA: 3s - loss: 0.143 - ETA: 3s - loss: 0.150 - ETA: 3s - loss: 0.151 - ETA: 3s - loss: 0.151 - ETA: 3s - loss: 0.149 - ETA: 2s - loss: 0.148 - ETA: 2s - loss: 0.149 - ETA: 2s - loss: 0.146 - ETA: 2s - loss: 0.147 - ETA: 2s - loss: 0.148 - ETA: 2s - loss: 0.148 - ETA: 2s - loss: 0.149 - ETA: 1s - loss: 0.148 - ETA: 1s - loss: 0.147 - ETA: 1s - loss: 0.147 - ETA: 1s - loss: 0.146 - ETA: 1s - loss: 0.147 - ETA: 1s - loss: 0.148 - ETA: 0s - loss: 0.149 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.147 - ETA: 0s - loss: 0.148 - ETA: 0s - loss: 0.148 - 5s 287us/step - loss: 0.1473\n",
      "\n",
      "Epoch 00011: loss improved from 0.18409 to 0.14726, saving model to models\\weights-improvement-11-bigger.hdf5\n",
      "Epoch 12/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.135 - ETA: 4s - loss: 0.119 - ETA: 4s - loss: 0.123 - ETA: 4s - loss: 0.121 - ETA: 4s - loss: 0.124 - ETA: 4s - loss: 0.126 - ETA: 3s - loss: 0.126 - ETA: 3s - loss: 0.127 - ETA: 3s - loss: 0.125 - ETA: 3s - loss: 0.125 - ETA: 3s - loss: 0.125 - ETA: 3s - loss: 0.125 - ETA: 3s - loss: 0.124 - ETA: 2s - loss: 0.125 - ETA: 2s - loss: 0.125 - ETA: 2s - loss: 0.123 - ETA: 2s - loss: 0.123 - ETA: 2s - loss: 0.122 - ETA: 2s - loss: 0.123 - ETA: 2s - loss: 0.123 - ETA: 1s - loss: 0.122 - ETA: 1s - loss: 0.122 - ETA: 1s - loss: 0.122 - ETA: 1s - loss: 0.123 - ETA: 1s - loss: 0.123 - ETA: 1s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.124 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.125 - ETA: 0s - loss: 0.126 - 5s 287us/step - loss: 0.1268\n",
      "\n",
      "Epoch 00012: loss improved from 0.14726 to 0.12675, saving model to models\\weights-improvement-12-bigger.hdf5\n",
      "Epoch 13/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.104 - ETA: 4s - loss: 0.105 - ETA: 4s - loss: 0.102 - ETA: 4s - loss: 0.103 - ETA: 4s - loss: 0.102 - ETA: 4s - loss: 0.103 - ETA: 3s - loss: 0.106 - ETA: 3s - loss: 0.104 - ETA: 3s - loss: 0.100 - ETA: 3s - loss: 0.103 - ETA: 3s - loss: 0.106 - ETA: 3s - loss: 0.105 - ETA: 3s - loss: 0.106 - ETA: 2s - loss: 0.106 - ETA: 2s - loss: 0.105 - ETA: 2s - loss: 0.106 - ETA: 2s - loss: 0.106 - ETA: 2s - loss: 0.105 - ETA: 2s - loss: 0.104 - ETA: 2s - loss: 0.104 - ETA: 1s - loss: 0.103 - ETA: 1s - loss: 0.102 - ETA: 1s - loss: 0.102 - ETA: 1s - loss: 0.102 - ETA: 1s - loss: 0.105 - ETA: 1s - loss: 0.104 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.105 - ETA: 0s - loss: 0.107 - ETA: 0s - loss: 0.106 - ETA: 0s - loss: 0.109 - ETA: 0s - loss: 0.110 - ETA: 0s - loss: 0.111 - 5s 289us/step - loss: 0.1122\n",
      "\n",
      "Epoch 00013: loss improved from 0.12675 to 0.11222, saving model to models\\weights-improvement-13-bigger.hdf5\n",
      "Epoch 14/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.134 - ETA: 4s - loss: 0.129 - ETA: 4s - loss: 0.121 - ETA: 4s - loss: 0.125 - ETA: 4s - loss: 0.120 - ETA: 4s - loss: 0.113 - ETA: 3s - loss: 0.110 - ETA: 3s - loss: 0.108 - ETA: 3s - loss: 0.112 - ETA: 3s - loss: 0.110 - ETA: 3s - loss: 0.108 - ETA: 3s - loss: 0.108 - ETA: 3s - loss: 0.109 - ETA: 2s - loss: 0.107 - ETA: 2s - loss: 0.106 - ETA: 2s - loss: 0.106 - ETA: 2s - loss: 0.107 - ETA: 2s - loss: 0.105 - ETA: 2s - loss: 0.104 - ETA: 2s - loss: 0.103 - ETA: 1s - loss: 0.105 - ETA: 1s - loss: 0.104 - ETA: 1s - loss: 0.104 - ETA: 1s - loss: 0.104 - ETA: 1s - loss: 0.103 - ETA: 1s - loss: 0.102 - ETA: 1s - loss: 0.101 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.100 - ETA: 0s - loss: 0.101 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.099 - ETA: 0s - loss: 0.100 - 5s 299us/step - loss: 0.1004\n",
      "\n",
      "Epoch 00014: loss improved from 0.11222 to 0.10039, saving model to models\\weights-improvement-14-bigger.hdf5\n",
      "Epoch 15/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.078 - ETA: 4s - loss: 0.086 - ETA: 4s - loss: 0.081 - ETA: 4s - loss: 0.079 - ETA: 4s - loss: 0.080 - ETA: 4s - loss: 0.081 - ETA: 3s - loss: 0.081 - ETA: 3s - loss: 0.078 - ETA: 3s - loss: 0.079 - ETA: 3s - loss: 0.080 - ETA: 3s - loss: 0.079 - ETA: 3s - loss: 0.080 - ETA: 3s - loss: 0.081 - ETA: 2s - loss: 0.080 - ETA: 2s - loss: 0.082 - ETA: 2s - loss: 0.080 - ETA: 2s - loss: 0.080 - ETA: 2s - loss: 0.079 - ETA: 2s - loss: 0.080 - ETA: 2s - loss: 0.080 - ETA: 1s - loss: 0.079 - ETA: 1s - loss: 0.078 - ETA: 1s - loss: 0.078 - ETA: 1s - loss: 0.078 - ETA: 1s - loss: 0.079 - ETA: 1s - loss: 0.079 - ETA: 1s - loss: 0.081 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.082 - ETA: 0s - loss: 0.081 - ETA: 0s - loss: 0.080 - ETA: 0s - loss: 0.081 - 5s 291us/step - loss: 0.0811\n",
      "\n",
      "Epoch 00015: loss improved from 0.10039 to 0.08112, saving model to models\\weights-improvement-15-bigger.hdf5\n",
      "Epoch 16/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.056 - ETA: 4s - loss: 0.058 - ETA: 4s - loss: 0.049 - ETA: 4s - loss: 0.049 - ETA: 4s - loss: 0.053 - ETA: 4s - loss: 0.055 - ETA: 3s - loss: 0.054 - ETA: 3s - loss: 0.056 - ETA: 3s - loss: 0.056 - ETA: 3s - loss: 0.058 - ETA: 3s - loss: 0.060 - ETA: 3s - loss: 0.060 - ETA: 3s - loss: 0.062 - ETA: 2s - loss: 0.061 - ETA: 2s - loss: 0.061 - ETA: 2s - loss: 0.061 - ETA: 2s - loss: 0.063 - ETA: 2s - loss: 0.065 - ETA: 2s - loss: 0.064 - ETA: 2s - loss: 0.063 - ETA: 1s - loss: 0.064 - ETA: 1s - loss: 0.063 - ETA: 1s - loss: 0.062 - ETA: 1s - loss: 0.063 - ETA: 1s - loss: 0.062 - ETA: 1s - loss: 0.063 - ETA: 1s - loss: 0.062 - ETA: 0s - loss: 0.063 - ETA: 0s - loss: 0.064 - ETA: 0s - loss: 0.065 - ETA: 0s - loss: 0.066 - ETA: 0s - loss: 0.066 - ETA: 0s - loss: 0.067 - 5s 291us/step - loss: 0.0671\n",
      "\n",
      "Epoch 00016: loss improved from 0.08112 to 0.06714, saving model to models\\weights-improvement-16-bigger.hdf5\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17286/17286 [==============================] - ETA: 4s - loss: 0.065 - ETA: 4s - loss: 0.066 - ETA: 4s - loss: 0.063 - ETA: 4s - loss: 0.062 - ETA: 4s - loss: 0.063 - ETA: 4s - loss: 0.069 - ETA: 3s - loss: 0.065 - ETA: 3s - loss: 0.064 - ETA: 3s - loss: 0.066 - ETA: 3s - loss: 0.066 - ETA: 3s - loss: 0.067 - ETA: 3s - loss: 0.066 - ETA: 3s - loss: 0.066 - ETA: 2s - loss: 0.063 - ETA: 2s - loss: 0.064 - ETA: 2s - loss: 0.065 - ETA: 2s - loss: 0.065 - ETA: 2s - loss: 0.063 - ETA: 2s - loss: 0.064 - ETA: 2s - loss: 0.064 - ETA: 1s - loss: 0.063 - ETA: 1s - loss: 0.064 - ETA: 1s - loss: 0.065 - ETA: 1s - loss: 0.066 - ETA: 1s - loss: 0.065 - ETA: 1s - loss: 0.066 - ETA: 0s - loss: 0.067 - ETA: 0s - loss: 0.067 - ETA: 0s - loss: 0.067 - ETA: 0s - loss: 0.067 - ETA: 0s - loss: 0.067 - ETA: 0s - loss: 0.067 - ETA: 0s - loss: 0.068 - 5s 287us/step - loss: 0.0684\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.06714\n",
      "Epoch 18/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.081 - ETA: 4s - loss: 0.078 - ETA: 4s - loss: 0.068 - ETA: 4s - loss: 0.062 - ETA: 4s - loss: 0.061 - ETA: 4s - loss: 0.060 - ETA: 3s - loss: 0.063 - ETA: 3s - loss: 0.065 - ETA: 3s - loss: 0.064 - ETA: 3s - loss: 0.063 - ETA: 3s - loss: 0.063 - ETA: 3s - loss: 0.062 - ETA: 3s - loss: 0.062 - ETA: 2s - loss: 0.063 - ETA: 2s - loss: 0.062 - ETA: 2s - loss: 0.063 - ETA: 2s - loss: 0.062 - ETA: 2s - loss: 0.062 - ETA: 2s - loss: 0.061 - ETA: 2s - loss: 0.063 - ETA: 1s - loss: 0.062 - ETA: 1s - loss: 0.063 - ETA: 1s - loss: 0.062 - ETA: 1s - loss: 0.062 - ETA: 1s - loss: 0.062 - ETA: 1s - loss: 0.062 - ETA: 0s - loss: 0.062 - ETA: 0s - loss: 0.062 - ETA: 0s - loss: 0.063 - ETA: 0s - loss: 0.063 - ETA: 0s - loss: 0.064 - ETA: 0s - loss: 0.063 - ETA: 0s - loss: 0.063 - 5s 287us/step - loss: 0.0632\n",
      "\n",
      "Epoch 00018: loss improved from 0.06714 to 0.06318, saving model to models\\weights-improvement-18-bigger.hdf5\n",
      "Epoch 19/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.052 - ETA: 4s - loss: 0.062 - ETA: 4s - loss: 0.058 - ETA: 4s - loss: 0.061 - ETA: 4s - loss: 0.066 - ETA: 4s - loss: 0.065 - ETA: 3s - loss: 0.065 - ETA: 3s - loss: 0.062 - ETA: 3s - loss: 0.061 - ETA: 3s - loss: 0.061 - ETA: 3s - loss: 0.061 - ETA: 3s - loss: 0.060 - ETA: 3s - loss: 0.060 - ETA: 2s - loss: 0.061 - ETA: 2s - loss: 0.063 - ETA: 2s - loss: 0.063 - ETA: 2s - loss: 0.064 - ETA: 2s - loss: 0.063 - ETA: 2s - loss: 0.063 - ETA: 2s - loss: 0.064 - ETA: 1s - loss: 0.063 - ETA: 1s - loss: 0.062 - ETA: 1s - loss: 0.062 - ETA: 1s - loss: 0.062 - ETA: 1s - loss: 0.061 - ETA: 1s - loss: 0.060 - ETA: 0s - loss: 0.061 - ETA: 0s - loss: 0.060 - ETA: 0s - loss: 0.060 - ETA: 0s - loss: 0.061 - ETA: 0s - loss: 0.061 - ETA: 0s - loss: 0.061 - ETA: 0s - loss: 0.061 - 5s 287us/step - loss: 0.0615\n",
      "\n",
      "Epoch 00019: loss improved from 0.06318 to 0.06155, saving model to models\\weights-improvement-19-bigger.hdf5\n",
      "Epoch 20/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.036 - ETA: 4s - loss: 0.042 - ETA: 4s - loss: 0.049 - ETA: 4s - loss: 0.046 - ETA: 4s - loss: 0.045 - ETA: 4s - loss: 0.048 - ETA: 3s - loss: 0.049 - ETA: 3s - loss: 0.052 - ETA: 3s - loss: 0.050 - ETA: 3s - loss: 0.050 - ETA: 3s - loss: 0.051 - ETA: 3s - loss: 0.050 - ETA: 3s - loss: 0.049 - ETA: 2s - loss: 0.050 - ETA: 2s - loss: 0.050 - ETA: 2s - loss: 0.049 - ETA: 2s - loss: 0.047 - ETA: 2s - loss: 0.047 - ETA: 2s - loss: 0.048 - ETA: 2s - loss: 0.048 - ETA: 1s - loss: 0.048 - ETA: 1s - loss: 0.048 - ETA: 1s - loss: 0.048 - ETA: 1s - loss: 0.047 - ETA: 1s - loss: 0.046 - ETA: 1s - loss: 0.046 - ETA: 0s - loss: 0.046 - ETA: 0s - loss: 0.046 - ETA: 0s - loss: 0.046 - ETA: 0s - loss: 0.046 - ETA: 0s - loss: 0.047 - ETA: 0s - loss: 0.046 - ETA: 0s - loss: 0.046 - 5s 288us/step - loss: 0.0462\n",
      "\n",
      "Epoch 00020: loss improved from 0.06155 to 0.04625, saving model to models\\weights-improvement-20-bigger.hdf5\n",
      "Epoch 21/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.082 - ETA: 4s - loss: 0.047 - ETA: 4s - loss: 0.043 - ETA: 4s - loss: 0.038 - ETA: 4s - loss: 0.040 - ETA: 4s - loss: 0.043 - ETA: 3s - loss: 0.044 - ETA: 3s - loss: 0.042 - ETA: 3s - loss: 0.041 - ETA: 3s - loss: 0.041 - ETA: 3s - loss: 0.043 - ETA: 3s - loss: 0.042 - ETA: 3s - loss: 0.043 - ETA: 2s - loss: 0.042 - ETA: 2s - loss: 0.041 - ETA: 2s - loss: 0.040 - ETA: 2s - loss: 0.041 - ETA: 2s - loss: 0.040 - ETA: 2s - loss: 0.040 - ETA: 2s - loss: 0.040 - ETA: 1s - loss: 0.039 - ETA: 1s - loss: 0.039 - ETA: 1s - loss: 0.039 - ETA: 1s - loss: 0.039 - ETA: 1s - loss: 0.039 - ETA: 1s - loss: 0.039 - ETA: 0s - loss: 0.038 - ETA: 0s - loss: 0.038 - ETA: 0s - loss: 0.039 - ETA: 0s - loss: 0.039 - ETA: 0s - loss: 0.039 - ETA: 0s - loss: 0.040 - ETA: 0s - loss: 0.040 - 5s 288us/step - loss: 0.0410\n",
      "\n",
      "Epoch 00021: loss improved from 0.04625 to 0.04101, saving model to models\\weights-improvement-21-bigger.hdf5\n",
      "Epoch 22/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.037 - ETA: 4s - loss: 0.029 - ETA: 4s - loss: 0.041 - ETA: 4s - loss: 0.038 - ETA: 4s - loss: 0.035 - ETA: 4s - loss: 0.033 - ETA: 3s - loss: 0.035 - ETA: 3s - loss: 0.035 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.033 - ETA: 3s - loss: 0.032 - ETA: 3s - loss: 0.033 - ETA: 2s - loss: 0.034 - ETA: 2s - loss: 0.036 - ETA: 2s - loss: 0.035 - ETA: 2s - loss: 0.037 - ETA: 2s - loss: 0.036 - ETA: 2s - loss: 0.036 - ETA: 2s - loss: 0.036 - ETA: 1s - loss: 0.036 - ETA: 1s - loss: 0.035 - ETA: 1s - loss: 0.036 - ETA: 1s - loss: 0.035 - ETA: 1s - loss: 0.035 - ETA: 1s - loss: 0.035 - ETA: 1s - loss: 0.036 - ETA: 0s - loss: 0.035 - ETA: 0s - loss: 0.035 - ETA: 0s - loss: 0.035 - ETA: 0s - loss: 0.035 - ETA: 0s - loss: 0.035 - ETA: 0s - loss: 0.035 - 5s 290us/step - loss: 0.0353\n",
      "\n",
      "Epoch 00022: loss improved from 0.04101 to 0.03530, saving model to models\\weights-improvement-22-bigger.hdf5\n",
      "Epoch 23/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.018 - ETA: 4s - loss: 0.032 - ETA: 4s - loss: 0.028 - ETA: 4s - loss: 0.030 - ETA: 4s - loss: 0.037 - ETA: 4s - loss: 0.035 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.037 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.035 - ETA: 3s - loss: 0.040 - ETA: 2s - loss: 0.040 - ETA: 2s - loss: 0.040 - ETA: 2s - loss: 0.039 - ETA: 2s - loss: 0.038 - ETA: 2s - loss: 0.038 - ETA: 2s - loss: 0.038 - ETA: 2s - loss: 0.038 - ETA: 1s - loss: 0.038 - ETA: 1s - loss: 0.039 - ETA: 1s - loss: 0.039 - ETA: 1s - loss: 0.039 - ETA: 1s - loss: 0.038 - ETA: 1s - loss: 0.038 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.036 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.038 - ETA: 0s - loss: 0.038 - ETA: 0s - loss: 0.038 - 5s 287us/step - loss: 0.0378\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.03530\n",
      "Epoch 24/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.049 - ETA: 4s - loss: 0.036 - ETA: 4s - loss: 0.038 - ETA: 4s - loss: 0.035 - ETA: 4s - loss: 0.031 - ETA: 4s - loss: 0.031 - ETA: 3s - loss: 0.032 - ETA: 3s - loss: 0.033 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.035 - ETA: 3s - loss: 0.034 - ETA: 2s - loss: 0.035 - ETA: 2s - loss: 0.035 - ETA: 2s - loss: 0.036 - ETA: 2s - loss: 0.036 - ETA: 2s - loss: 0.036 - ETA: 2s - loss: 0.037 - ETA: 2s - loss: 0.036 - ETA: 1s - loss: 0.036 - ETA: 1s - loss: 0.036 - ETA: 1s - loss: 0.036 - ETA: 1s - loss: 0.036 - ETA: 1s - loss: 0.036 - ETA: 1s - loss: 0.036 - ETA: 0s - loss: 0.036 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.036 - ETA: 0s - loss: 0.036 - ETA: 0s - loss: 0.036 - ETA: 0s - loss: 0.036 - 5s 288us/step - loss: 0.0360\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.03530\n",
      "Epoch 25/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.023 - ETA: 4s - loss: 0.030 - ETA: 4s - loss: 0.025 - ETA: 4s - loss: 0.034 - ETA: 4s - loss: 0.034 - ETA: 4s - loss: 0.036 - ETA: 3s - loss: 0.036 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.033 - ETA: 3s - loss: 0.036 - ETA: 3s - loss: 0.036 - ETA: 3s - loss: 0.037 - ETA: 3s - loss: 0.037 - ETA: 2s - loss: 0.036 - ETA: 2s - loss: 0.038 - ETA: 2s - loss: 0.038 - ETA: 2s - loss: 0.038 - ETA: 2s - loss: 0.038 - ETA: 2s - loss: 0.038 - ETA: 2s - loss: 0.039 - ETA: 1s - loss: 0.038 - ETA: 1s - loss: 0.039 - ETA: 1s - loss: 0.039 - ETA: 1s - loss: 0.039 - ETA: 1s - loss: 0.039 - ETA: 1s - loss: 0.038 - ETA: 0s - loss: 0.038 - ETA: 0s - loss: 0.039 - ETA: 0s - loss: 0.039 - ETA: 0s - loss: 0.039 - ETA: 0s - loss: 0.039 - ETA: 0s - loss: 0.039 - ETA: 0s - loss: 0.038 - 5s 288us/step - loss: 0.0382\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.03530\n",
      "Epoch 26/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.029 - ETA: 4s - loss: 0.038 - ETA: 4s - loss: 0.030 - ETA: 4s - loss: 0.029 - ETA: 4s - loss: 0.033 - ETA: 4s - loss: 0.034 - ETA: 3s - loss: 0.032 - ETA: 3s - loss: 0.031 - ETA: 3s - loss: 0.033 - ETA: 3s - loss: 0.032 - ETA: 3s - loss: 0.030 - ETA: 3s - loss: 0.031 - ETA: 3s - loss: 0.033 - ETA: 2s - loss: 0.032 - ETA: 2s - loss: 0.032 - ETA: 2s - loss: 0.032 - ETA: 2s - loss: 0.033 - ETA: 2s - loss: 0.032 - ETA: 2s - loss: 0.033 - ETA: 2s - loss: 0.034 - ETA: 1s - loss: 0.034 - ETA: 1s - loss: 0.033 - ETA: 1s - loss: 0.033 - ETA: 1s - loss: 0.034 - ETA: 1s - loss: 0.035 - ETA: 1s - loss: 0.036 - ETA: 0s - loss: 0.036 - ETA: 0s - loss: 0.035 - ETA: 0s - loss: 0.035 - ETA: 0s - loss: 0.036 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.036 - ETA: 0s - loss: 0.037 - 5s 287us/step - loss: 0.0369\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.03530\n",
      "Epoch 27/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.061 - ETA: 4s - loss: 0.042 - ETA: 4s - loss: 0.036 - ETA: 4s - loss: 0.036 - ETA: 4s - loss: 0.033 - ETA: 4s - loss: 0.033 - ETA: 3s - loss: 0.031 - ETA: 3s - loss: 0.032 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.033 - ETA: 3s - loss: 0.035 - ETA: 3s - loss: 0.035 - ETA: 3s - loss: 0.036 - ETA: 2s - loss: 0.037 - ETA: 2s - loss: 0.038 - ETA: 2s - loss: 0.037 - ETA: 2s - loss: 0.036 - ETA: 2s - loss: 0.037 - ETA: 2s - loss: 0.037 - ETA: 2s - loss: 0.037 - ETA: 1s - loss: 0.037 - ETA: 1s - loss: 0.037 - ETA: 1s - loss: 0.037 - ETA: 1s - loss: 0.037 - ETA: 1s - loss: 0.036 - ETA: 1s - loss: 0.037 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.038 - ETA: 0s - loss: 0.038 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.036 - ETA: 0s - loss: 0.036 - 5s 286us/step - loss: 0.0367\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.03530\n",
      "Epoch 28/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.048 - ETA: 4s - loss: 0.033 - ETA: 4s - loss: 0.039 - ETA: 4s - loss: 0.032 - ETA: 4s - loss: 0.031 - ETA: 4s - loss: 0.035 - ETA: 3s - loss: 0.035 - ETA: 3s - loss: 0.036 - ETA: 3s - loss: 0.037 - ETA: 3s - loss: 0.035 - ETA: 3s - loss: 0.033 - ETA: 3s - loss: 0.032 - ETA: 3s - loss: 0.033 - ETA: 2s - loss: 0.033 - ETA: 2s - loss: 0.034 - ETA: 2s - loss: 0.034 - ETA: 2s - loss: 0.033 - ETA: 2s - loss: 0.033 - ETA: 2s - loss: 0.034 - ETA: 2s - loss: 0.035 - ETA: 1s - loss: 0.034 - ETA: 1s - loss: 0.034 - ETA: 1s - loss: 0.035 - ETA: 1s - loss: 0.035 - ETA: 1s - loss: 0.036 - ETA: 1s - loss: 0.036 - ETA: 0s - loss: 0.036 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.036 - ETA: 0s - loss: 0.036 - ETA: 0s - loss: 0.036 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.037 - 5s 286us/step - loss: 0.0372\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.03530\n",
      "Epoch 29/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.026 - ETA: 4s - loss: 0.033 - ETA: 4s - loss: 0.033 - ETA: 4s - loss: 0.033 - ETA: 4s - loss: 0.031 - ETA: 4s - loss: 0.034 - ETA: 3s - loss: 0.034 - ETA: 3s - loss: 0.032 - ETA: 3s - loss: 0.031 - ETA: 3s - loss: 0.030 - ETA: 3s - loss: 0.030 - ETA: 3s - loss: 0.032 - ETA: 3s - loss: 0.035 - ETA: 2s - loss: 0.034 - ETA: 2s - loss: 0.036 - ETA: 2s - loss: 0.037 - ETA: 2s - loss: 0.036 - ETA: 2s - loss: 0.036 - ETA: 2s - loss: 0.035 - ETA: 2s - loss: 0.035 - ETA: 1s - loss: 0.036 - ETA: 1s - loss: 0.035 - ETA: 1s - loss: 0.037 - ETA: 1s - loss: 0.036 - ETA: 1s - loss: 0.036 - ETA: 1s - loss: 0.037 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.037 - ETA: 0s - loss: 0.038 - ETA: 0s - loss: 0.038 - 5s 286us/step - loss: 0.0381\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.03530\n",
      "Epoch 30/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.026 - ETA: 4s - loss: 0.020 - ETA: 4s - loss: 0.026 - ETA: 4s - loss: 0.027 - ETA: 4s - loss: 0.029 - ETA: 4s - loss: 0.027 - ETA: 3s - loss: 0.025 - ETA: 3s - loss: 0.026 - ETA: 3s - loss: 0.025 - ETA: 3s - loss: 0.027 - ETA: 3s - loss: 0.027 - ETA: 3s - loss: 0.027 - ETA: 3s - loss: 0.027 - ETA: 2s - loss: 0.027 - ETA: 2s - loss: 0.027 - ETA: 2s - loss: 0.027 - ETA: 2s - loss: 0.028 - ETA: 2s - loss: 0.028 - ETA: 2s - loss: 0.027 - ETA: 2s - loss: 0.028 - ETA: 1s - loss: 0.028 - ETA: 1s - loss: 0.028 - ETA: 1s - loss: 0.029 - ETA: 1s - loss: 0.029 - ETA: 1s - loss: 0.028 - ETA: 1s - loss: 0.029 - ETA: 0s - loss: 0.028 - ETA: 0s - loss: 0.029 - ETA: 0s - loss: 0.029 - ETA: 0s - loss: 0.029 - ETA: 0s - loss: 0.029 - ETA: 0s - loss: 0.030 - ETA: 0s - loss: 0.030 - 5s 286us/step - loss: 0.0302\n",
      "\n",
      "Epoch 00030: loss improved from 0.03530 to 0.03016, saving model to models\\weights-improvement-30-bigger.hdf5\n",
      "Epoch 31/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.020 - ETA: 4s - loss: 0.029 - ETA: 4s - loss: 0.028 - ETA: 4s - loss: 0.028 - ETA: 4s - loss: 0.028 - ETA: 4s - loss: 0.027 - ETA: 3s - loss: 0.025 - ETA: 3s - loss: 0.023 - ETA: 3s - loss: 0.023 - ETA: 3s - loss: 0.024 - ETA: 3s - loss: 0.023 - ETA: 3s - loss: 0.024 - ETA: 3s - loss: 0.023 - ETA: 2s - loss: 0.022 - ETA: 2s - loss: 0.022 - ETA: 2s - loss: 0.022 - ETA: 2s - loss: 0.023 - ETA: 2s - loss: 0.024 - ETA: 2s - loss: 0.024 - ETA: 2s - loss: 0.024 - ETA: 1s - loss: 0.023 - ETA: 1s - loss: 0.023 - ETA: 1s - loss: 0.023 - ETA: 1s - loss: 0.023 - ETA: 1s - loss: 0.022 - ETA: 1s - loss: 0.023 - ETA: 0s - loss: 0.023 - ETA: 0s - loss: 0.023 - ETA: 0s - loss: 0.023 - ETA: 0s - loss: 0.023 - ETA: 0s - loss: 0.023 - ETA: 0s - loss: 0.024 - ETA: 0s - loss: 0.024 - 5s 286us/step - loss: 0.0245\n",
      "\n",
      "Epoch 00031: loss improved from 0.03016 to 0.02451, saving model to models\\weights-improvement-31-bigger.hdf5\n",
      "Epoch 32/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.023 - ETA: 4s - loss: 0.021 - ETA: 4s - loss: 0.025 - ETA: 4s - loss: 0.025 - ETA: 4s - loss: 0.023 - ETA: 4s - loss: 0.024 - ETA: 3s - loss: 0.023 - ETA: 3s - loss: 0.029 - ETA: 3s - loss: 0.027 - ETA: 3s - loss: 0.028 - ETA: 3s - loss: 0.026 - ETA: 3s - loss: 0.026 - ETA: 3s - loss: 0.026 - ETA: 2s - loss: 0.025 - ETA: 2s - loss: 0.026 - ETA: 2s - loss: 0.026 - ETA: 2s - loss: 0.026 - ETA: 2s - loss: 0.025 - ETA: 2s - loss: 0.025 - ETA: 2s - loss: 0.024 - ETA: 1s - loss: 0.024 - ETA: 1s - loss: 0.023 - ETA: 1s - loss: 0.022 - ETA: 1s - loss: 0.022 - ETA: 1s - loss: 0.022 - ETA: 1s - loss: 0.022 - ETA: 0s - loss: 0.021 - ETA: 0s - loss: 0.022 - ETA: 0s - loss: 0.021 - ETA: 0s - loss: 0.021 - ETA: 0s - loss: 0.021 - ETA: 0s - loss: 0.021 - ETA: 0s - loss: 0.021 - 5s 288us/step - loss: 0.0213\n",
      "\n",
      "Epoch 00032: loss improved from 0.02451 to 0.02126, saving model to models\\weights-improvement-32-bigger.hdf5\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17286/17286 [==============================] - ETA: 4s - loss: 0.019 - ETA: 4s - loss: 0.015 - ETA: 4s - loss: 0.015 - ETA: 4s - loss: 0.017 - ETA: 4s - loss: 0.018 - ETA: 4s - loss: 0.018 - ETA: 3s - loss: 0.017 - ETA: 3s - loss: 0.018 - ETA: 3s - loss: 0.017 - ETA: 3s - loss: 0.017 - ETA: 3s - loss: 0.017 - ETA: 3s - loss: 0.017 - ETA: 3s - loss: 0.016 - ETA: 2s - loss: 0.016 - ETA: 2s - loss: 0.016 - ETA: 2s - loss: 0.017 - ETA: 2s - loss: 0.016 - ETA: 2s - loss: 0.017 - ETA: 2s - loss: 0.017 - ETA: 2s - loss: 0.017 - ETA: 1s - loss: 0.017 - ETA: 1s - loss: 0.017 - ETA: 1s - loss: 0.017 - ETA: 1s - loss: 0.017 - ETA: 1s - loss: 0.016 - ETA: 1s - loss: 0.017 - ETA: 0s - loss: 0.017 - ETA: 0s - loss: 0.017 - ETA: 0s - loss: 0.017 - ETA: 0s - loss: 0.017 - ETA: 0s - loss: 0.017 - ETA: 0s - loss: 0.017 - ETA: 0s - loss: 0.017 - 5s 286us/step - loss: 0.0178\n",
      "\n",
      "Epoch 00033: loss improved from 0.02126 to 0.01783, saving model to models\\weights-improvement-33-bigger.hdf5\n",
      "Epoch 34/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.010 - ETA: 4s - loss: 0.015 - ETA: 4s - loss: 0.014 - ETA: 4s - loss: 0.013 - ETA: 4s - loss: 0.013 - ETA: 4s - loss: 0.014 - ETA: 3s - loss: 0.014 - ETA: 3s - loss: 0.013 - ETA: 3s - loss: 0.013 - ETA: 3s - loss: 0.015 - ETA: 3s - loss: 0.015 - ETA: 3s - loss: 0.014 - ETA: 3s - loss: 0.014 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.014 - ETA: 1s - loss: 0.014 - ETA: 1s - loss: 0.014 - ETA: 1s - loss: 0.014 - ETA: 1s - loss: 0.014 - ETA: 1s - loss: 0.014 - ETA: 1s - loss: 0.014 - ETA: 0s - loss: 0.014 - ETA: 0s - loss: 0.014 - ETA: 0s - loss: 0.014 - ETA: 0s - loss: 0.014 - ETA: 0s - loss: 0.014 - ETA: 0s - loss: 0.014 - ETA: 0s - loss: 0.014 - 5s 286us/step - loss: 0.0145\n",
      "\n",
      "Epoch 00034: loss improved from 0.01783 to 0.01454, saving model to models\\weights-improvement-34-bigger.hdf5\n",
      "Epoch 35/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.011 - ETA: 4s - loss: 0.020 - ETA: 4s - loss: 0.020 - ETA: 4s - loss: 0.019 - ETA: 4s - loss: 0.017 - ETA: 4s - loss: 0.016 - ETA: 3s - loss: 0.017 - ETA: 3s - loss: 0.016 - ETA: 3s - loss: 0.015 - ETA: 3s - loss: 0.015 - ETA: 3s - loss: 0.015 - ETA: 3s - loss: 0.014 - ETA: 3s - loss: 0.014 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.013 - ETA: 1s - loss: 0.013 - ETA: 1s - loss: 0.013 - ETA: 1s - loss: 0.013 - ETA: 1s - loss: 0.013 - ETA: 1s - loss: 0.013 - ETA: 1s - loss: 0.013 - ETA: 1s - loss: 0.012 - ETA: 0s - loss: 0.012 - ETA: 0s - loss: 0.012 - ETA: 0s - loss: 0.012 - ETA: 0s - loss: 0.013 - ETA: 0s - loss: 0.012 - ETA: 0s - loss: 0.013 - 5s 290us/step - loss: 0.0130\n",
      "\n",
      "Epoch 00035: loss improved from 0.01454 to 0.01299, saving model to models\\weights-improvement-35-bigger.hdf5\n",
      "Epoch 36/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.011 - ETA: 4s - loss: 0.009 - ETA: 4s - loss: 0.010 - ETA: 4s - loss: 0.010 - ETA: 4s - loss: 0.011 - ETA: 4s - loss: 0.011 - ETA: 3s - loss: 0.010 - ETA: 3s - loss: 0.011 - ETA: 3s - loss: 0.011 - ETA: 3s - loss: 0.012 - ETA: 3s - loss: 0.012 - ETA: 3s - loss: 0.012 - ETA: 3s - loss: 0.012 - ETA: 2s - loss: 0.012 - ETA: 2s - loss: 0.012 - ETA: 2s - loss: 0.012 - ETA: 2s - loss: 0.012 - ETA: 2s - loss: 0.012 - ETA: 2s - loss: 0.012 - ETA: 2s - loss: 0.012 - ETA: 1s - loss: 0.012 - ETA: 1s - loss: 0.012 - ETA: 1s - loss: 0.011 - ETA: 1s - loss: 0.012 - ETA: 1s - loss: 0.012 - ETA: 1s - loss: 0.012 - ETA: 0s - loss: 0.012 - ETA: 0s - loss: 0.012 - ETA: 0s - loss: 0.012 - ETA: 0s - loss: 0.012 - ETA: 0s - loss: 0.012 - ETA: 0s - loss: 0.012 - ETA: 0s - loss: 0.012 - 5s 288us/step - loss: 0.0128\n",
      "\n",
      "Epoch 00036: loss improved from 0.01299 to 0.01277, saving model to models\\weights-improvement-36-bigger.hdf5\n",
      "Epoch 37/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.010 - ETA: 4s - loss: 0.015 - ETA: 4s - loss: 0.020 - ETA: 4s - loss: 0.023 - ETA: 4s - loss: 0.020 - ETA: 4s - loss: 0.019 - ETA: 3s - loss: 0.019 - ETA: 3s - loss: 0.019 - ETA: 3s - loss: 0.018 - ETA: 3s - loss: 0.017 - ETA: 3s - loss: 0.016 - ETA: 3s - loss: 0.016 - ETA: 3s - loss: 0.016 - ETA: 2s - loss: 0.017 - ETA: 2s - loss: 0.018 - ETA: 2s - loss: 0.018 - ETA: 2s - loss: 0.018 - ETA: 2s - loss: 0.018 - ETA: 2s - loss: 0.018 - ETA: 2s - loss: 0.019 - ETA: 1s - loss: 0.019 - ETA: 1s - loss: 0.018 - ETA: 1s - loss: 0.018 - ETA: 1s - loss: 0.019 - ETA: 1s - loss: 0.018 - ETA: 1s - loss: 0.018 - ETA: 1s - loss: 0.018 - ETA: 0s - loss: 0.018 - ETA: 0s - loss: 0.018 - ETA: 0s - loss: 0.018 - ETA: 0s - loss: 0.018 - ETA: 0s - loss: 0.018 - ETA: 0s - loss: 0.018 - 5s 290us/step - loss: 0.0185\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.01277\n",
      "Epoch 38/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.011 - ETA: 4s - loss: 0.011 - ETA: 4s - loss: 0.010 - ETA: 4s - loss: 0.015 - ETA: 4s - loss: 0.014 - ETA: 4s - loss: 0.013 - ETA: 3s - loss: 0.017 - ETA: 3s - loss: 0.018 - ETA: 3s - loss: 0.018 - ETA: 3s - loss: 0.019 - ETA: 3s - loss: 0.020 - ETA: 3s - loss: 0.019 - ETA: 3s - loss: 0.020 - ETA: 2s - loss: 0.020 - ETA: 2s - loss: 0.020 - ETA: 2s - loss: 0.019 - ETA: 2s - loss: 0.019 - ETA: 2s - loss: 0.020 - ETA: 2s - loss: 0.019 - ETA: 2s - loss: 0.021 - ETA: 1s - loss: 0.022 - ETA: 1s - loss: 0.022 - ETA: 1s - loss: 0.022 - ETA: 1s - loss: 0.024 - ETA: 1s - loss: 0.024 - ETA: 1s - loss: 0.024 - ETA: 0s - loss: 0.024 - ETA: 0s - loss: 0.024 - ETA: 0s - loss: 0.024 - ETA: 0s - loss: 0.024 - ETA: 0s - loss: 0.025 - ETA: 0s - loss: 0.025 - ETA: 0s - loss: 0.025 - 5s 287us/step - loss: 0.0258\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.01277\n",
      "Epoch 39/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.025 - ETA: 4s - loss: 0.039 - ETA: 4s - loss: 0.039 - ETA: 4s - loss: 0.038 - ETA: 4s - loss: 0.032 - ETA: 4s - loss: 0.034 - ETA: 3s - loss: 0.031 - ETA: 3s - loss: 0.029 - ETA: 3s - loss: 0.029 - ETA: 3s - loss: 0.027 - ETA: 3s - loss: 0.026 - ETA: 3s - loss: 0.026 - ETA: 3s - loss: 0.026 - ETA: 2s - loss: 0.026 - ETA: 2s - loss: 0.026 - ETA: 2s - loss: 0.025 - ETA: 2s - loss: 0.025 - ETA: 2s - loss: 0.025 - ETA: 2s - loss: 0.025 - ETA: 2s - loss: 0.024 - ETA: 1s - loss: 0.024 - ETA: 1s - loss: 0.024 - ETA: 1s - loss: 0.024 - ETA: 1s - loss: 0.024 - ETA: 1s - loss: 0.024 - ETA: 1s - loss: 0.024 - ETA: 0s - loss: 0.024 - ETA: 0s - loss: 0.024 - ETA: 0s - loss: 0.024 - ETA: 0s - loss: 0.024 - ETA: 0s - loss: 0.024 - ETA: 0s - loss: 0.024 - ETA: 0s - loss: 0.025 - 5s 286us/step - loss: 0.0251\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.01277\n",
      "Epoch 40/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.034 - ETA: 4s - loss: 0.028 - ETA: 4s - loss: 0.035 - ETA: 4s - loss: 0.028 - ETA: 4s - loss: 0.025 - ETA: 4s - loss: 0.024 - ETA: 3s - loss: 0.022 - ETA: 3s - loss: 0.024 - ETA: 3s - loss: 0.024 - ETA: 3s - loss: 0.025 - ETA: 3s - loss: 0.023 - ETA: 3s - loss: 0.022 - ETA: 3s - loss: 0.021 - ETA: 2s - loss: 0.021 - ETA: 2s - loss: 0.021 - ETA: 2s - loss: 0.021 - ETA: 2s - loss: 0.021 - ETA: 2s - loss: 0.021 - ETA: 2s - loss: 0.020 - ETA: 2s - loss: 0.020 - ETA: 1s - loss: 0.019 - ETA: 1s - loss: 0.019 - ETA: 1s - loss: 0.019 - ETA: 1s - loss: 0.019 - ETA: 1s - loss: 0.019 - ETA: 1s - loss: 0.019 - ETA: 0s - loss: 0.019 - ETA: 0s - loss: 0.019 - ETA: 0s - loss: 0.019 - ETA: 0s - loss: 0.019 - ETA: 0s - loss: 0.018 - ETA: 0s - loss: 0.019 - ETA: 0s - loss: 0.018 - 5s 287us/step - loss: 0.0186\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.01277\n",
      "Epoch 41/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.013 - ETA: 4s - loss: 0.013 - ETA: 4s - loss: 0.010 - ETA: 4s - loss: 0.009 - ETA: 4s - loss: 0.009 - ETA: 4s - loss: 0.009 - ETA: 3s - loss: 0.009 - ETA: 3s - loss: 0.008 - ETA: 3s - loss: 0.008 - ETA: 3s - loss: 0.008 - ETA: 3s - loss: 0.010 - ETA: 3s - loss: 0.009 - ETA: 3s - loss: 0.010 - ETA: 2s - loss: 0.010 - ETA: 2s - loss: 0.010 - ETA: 2s - loss: 0.010 - ETA: 2s - loss: 0.010 - ETA: 2s - loss: 0.010 - ETA: 2s - loss: 0.010 - ETA: 2s - loss: 0.010 - ETA: 1s - loss: 0.010 - ETA: 1s - loss: 0.010 - ETA: 1s - loss: 0.010 - ETA: 1s - loss: 0.010 - ETA: 1s - loss: 0.010 - ETA: 1s - loss: 0.010 - ETA: 0s - loss: 0.011 - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.011 - ETA: 0s - loss: 0.011 - ETA: 0s - loss: 0.011 - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.010 - 5s 286us/step - loss: 0.0108\n",
      "\n",
      "Epoch 00041: loss improved from 0.01277 to 0.01083, saving model to models\\weights-improvement-41-bigger.hdf5\n",
      "Epoch 42/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.005 - ETA: 4s - loss: 0.005 - ETA: 4s - loss: 0.005 - ETA: 4s - loss: 0.005 - ETA: 4s - loss: 0.006 - ETA: 4s - loss: 0.006 - ETA: 3s - loss: 0.006 - ETA: 3s - loss: 0.007 - ETA: 3s - loss: 0.007 - ETA: 3s - loss: 0.007 - ETA: 3s - loss: 0.007 - ETA: 3s - loss: 0.006 - ETA: 3s - loss: 0.006 - ETA: 2s - loss: 0.006 - ETA: 2s - loss: 0.006 - ETA: 2s - loss: 0.006 - ETA: 2s - loss: 0.006 - ETA: 2s - loss: 0.006 - ETA: 2s - loss: 0.006 - ETA: 2s - loss: 0.006 - ETA: 1s - loss: 0.006 - ETA: 1s - loss: 0.006 - ETA: 1s - loss: 0.006 - ETA: 1s - loss: 0.006 - ETA: 1s - loss: 0.006 - ETA: 1s - loss: 0.007 - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 5s 286us/step - loss: 0.0068\n",
      "\n",
      "Epoch 00042: loss improved from 0.01083 to 0.00677, saving model to models\\weights-improvement-42-bigger.hdf5\n",
      "Epoch 43/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.003 - ETA: 4s - loss: 0.004 - ETA: 4s - loss: 0.006 - ETA: 4s - loss: 0.007 - ETA: 4s - loss: 0.008 - ETA: 4s - loss: 0.008 - ETA: 3s - loss: 0.007 - ETA: 3s - loss: 0.007 - ETA: 3s - loss: 0.007 - ETA: 3s - loss: 0.009 - ETA: 3s - loss: 0.009 - ETA: 3s - loss: 0.009 - ETA: 3s - loss: 0.008 - ETA: 2s - loss: 0.008 - ETA: 2s - loss: 0.008 - ETA: 2s - loss: 0.008 - ETA: 2s - loss: 0.008 - ETA: 2s - loss: 0.008 - ETA: 2s - loss: 0.008 - ETA: 2s - loss: 0.008 - ETA: 1s - loss: 0.007 - ETA: 1s - loss: 0.007 - ETA: 1s - loss: 0.007 - ETA: 1s - loss: 0.007 - ETA: 1s - loss: 0.007 - ETA: 1s - loss: 0.007 - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.007 - 5s 286us/step - loss: 0.0072\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00677\n",
      "Epoch 44/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.016 - ETA: 4s - loss: 0.011 - ETA: 4s - loss: 0.008 - ETA: 4s - loss: 0.006 - ETA: 4s - loss: 0.006 - ETA: 4s - loss: 0.010 - ETA: 3s - loss: 0.011 - ETA: 3s - loss: 0.010 - ETA: 3s - loss: 0.009 - ETA: 3s - loss: 0.010 - ETA: 3s - loss: 0.010 - ETA: 3s - loss: 0.012 - ETA: 3s - loss: 0.012 - ETA: 2s - loss: 0.011 - ETA: 2s - loss: 0.011 - ETA: 2s - loss: 0.011 - ETA: 2s - loss: 0.011 - ETA: 2s - loss: 0.010 - ETA: 2s - loss: 0.011 - ETA: 2s - loss: 0.010 - ETA: 1s - loss: 0.010 - ETA: 1s - loss: 0.010 - ETA: 1s - loss: 0.010 - ETA: 1s - loss: 0.010 - ETA: 1s - loss: 0.010 - ETA: 1s - loss: 0.010 - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.010 - 5s 286us/step - loss: 0.0101\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00677\n",
      "Epoch 45/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.018 - ETA: 4s - loss: 0.010 - ETA: 4s - loss: 0.012 - ETA: 4s - loss: 0.009 - ETA: 4s - loss: 0.013 - ETA: 4s - loss: 0.011 - ETA: 3s - loss: 0.010 - ETA: 3s - loss: 0.010 - ETA: 3s - loss: 0.010 - ETA: 3s - loss: 0.010 - ETA: 3s - loss: 0.009 - ETA: 3s - loss: 0.009 - ETA: 3s - loss: 0.010 - ETA: 2s - loss: 0.009 - ETA: 2s - loss: 0.010 - ETA: 2s - loss: 0.010 - ETA: 2s - loss: 0.010 - ETA: 2s - loss: 0.010 - ETA: 2s - loss: 0.010 - ETA: 2s - loss: 0.009 - ETA: 1s - loss: 0.009 - ETA: 1s - loss: 0.010 - ETA: 1s - loss: 0.009 - ETA: 1s - loss: 0.009 - ETA: 1s - loss: 0.010 - ETA: 1s - loss: 0.010 - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.011 - ETA: 0s - loss: 0.011 - ETA: 0s - loss: 0.011 - 5s 286us/step - loss: 0.0112\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00677\n",
      "Epoch 46/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.004 - ETA: 4s - loss: 0.009 - ETA: 4s - loss: 0.007 - ETA: 4s - loss: 0.008 - ETA: 4s - loss: 0.008 - ETA: 4s - loss: 0.011 - ETA: 3s - loss: 0.011 - ETA: 3s - loss: 0.011 - ETA: 3s - loss: 0.011 - ETA: 3s - loss: 0.013 - ETA: 3s - loss: 0.014 - ETA: 3s - loss: 0.013 - ETA: 3s - loss: 0.014 - ETA: 2s - loss: 0.013 - ETA: 2s - loss: 0.013 - ETA: 2s - loss: 0.013 - ETA: 2s - loss: 0.013 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.013 - ETA: 2s - loss: 0.013 - ETA: 1s - loss: 0.013 - ETA: 1s - loss: 0.013 - ETA: 1s - loss: 0.013 - ETA: 1s - loss: 0.013 - ETA: 1s - loss: 0.013 - ETA: 1s - loss: 0.013 - ETA: 0s - loss: 0.014 - ETA: 0s - loss: 0.014 - ETA: 0s - loss: 0.014 - ETA: 0s - loss: 0.014 - ETA: 0s - loss: 0.014 - ETA: 0s - loss: 0.014 - ETA: 0s - loss: 0.014 - 5s 286us/step - loss: 0.0141\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00677\n",
      "Epoch 47/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.025 - ETA: 4s - loss: 0.023 - ETA: 4s - loss: 0.016 - ETA: 4s - loss: 0.015 - ETA: 4s - loss: 0.016 - ETA: 4s - loss: 0.015 - ETA: 3s - loss: 0.020 - ETA: 3s - loss: 0.021 - ETA: 3s - loss: 0.020 - ETA: 3s - loss: 0.020 - ETA: 3s - loss: 0.020 - ETA: 3s - loss: 0.020 - ETA: 3s - loss: 0.021 - ETA: 2s - loss: 0.022 - ETA: 2s - loss: 0.021 - ETA: 2s - loss: 0.021 - ETA: 2s - loss: 0.020 - ETA: 2s - loss: 0.020 - ETA: 2s - loss: 0.020 - ETA: 2s - loss: 0.019 - ETA: 1s - loss: 0.019 - ETA: 1s - loss: 0.019 - ETA: 1s - loss: 0.019 - ETA: 1s - loss: 0.019 - ETA: 1s - loss: 0.020 - ETA: 1s - loss: 0.020 - ETA: 0s - loss: 0.020 - ETA: 0s - loss: 0.020 - ETA: 0s - loss: 0.020 - ETA: 0s - loss: 0.020 - ETA: 0s - loss: 0.020 - ETA: 0s - loss: 0.020 - ETA: 0s - loss: 0.020 - 5s 287us/step - loss: 0.0199\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00677\n",
      "Epoch 48/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.013 - ETA: 4s - loss: 0.020 - ETA: 4s - loss: 0.016 - ETA: 4s - loss: 0.016 - ETA: 4s - loss: 0.019 - ETA: 4s - loss: 0.022 - ETA: 3s - loss: 0.019 - ETA: 3s - loss: 0.019 - ETA: 3s - loss: 0.021 - ETA: 3s - loss: 0.019 - ETA: 3s - loss: 0.019 - ETA: 3s - loss: 0.020 - ETA: 3s - loss: 0.020 - ETA: 2s - loss: 0.020 - ETA: 2s - loss: 0.020 - ETA: 2s - loss: 0.020 - ETA: 2s - loss: 0.019 - ETA: 2s - loss: 0.019 - ETA: 2s - loss: 0.019 - ETA: 2s - loss: 0.019 - ETA: 1s - loss: 0.019 - ETA: 1s - loss: 0.021 - ETA: 1s - loss: 0.020 - ETA: 1s - loss: 0.021 - ETA: 1s - loss: 0.021 - ETA: 1s - loss: 0.021 - ETA: 0s - loss: 0.021 - ETA: 0s - loss: 0.021 - ETA: 0s - loss: 0.021 - ETA: 0s - loss: 0.021 - ETA: 0s - loss: 0.020 - ETA: 0s - loss: 0.020 - ETA: 0s - loss: 0.020 - 5s 286us/step - loss: 0.0211\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00677\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17286/17286 [==============================] - ETA: 4s - loss: 0.030 - ETA: 4s - loss: 0.030 - ETA: 4s - loss: 0.025 - ETA: 4s - loss: 0.021 - ETA: 4s - loss: 0.017 - ETA: 4s - loss: 0.016 - ETA: 3s - loss: 0.019 - ETA: 3s - loss: 0.017 - ETA: 3s - loss: 0.020 - ETA: 3s - loss: 0.020 - ETA: 3s - loss: 0.021 - ETA: 3s - loss: 0.022 - ETA: 3s - loss: 0.022 - ETA: 2s - loss: 0.022 - ETA: 2s - loss: 0.022 - ETA: 2s - loss: 0.022 - ETA: 2s - loss: 0.022 - ETA: 2s - loss: 0.022 - ETA: 2s - loss: 0.021 - ETA: 2s - loss: 0.021 - ETA: 1s - loss: 0.021 - ETA: 1s - loss: 0.021 - ETA: 1s - loss: 0.021 - ETA: 1s - loss: 0.022 - ETA: 1s - loss: 0.022 - ETA: 1s - loss: 0.021 - ETA: 0s - loss: 0.022 - ETA: 0s - loss: 0.021 - ETA: 0s - loss: 0.021 - ETA: 0s - loss: 0.021 - ETA: 0s - loss: 0.021 - ETA: 0s - loss: 0.021 - ETA: 0s - loss: 0.021 - 5s 287us/step - loss: 0.0214\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00677\n",
      "Epoch 50/50\n",
      "17286/17286 [==============================] - ETA: 4s - loss: 0.006 - ETA: 4s - loss: 0.008 - ETA: 4s - loss: 0.007 - ETA: 4s - loss: 0.007 - ETA: 4s - loss: 0.009 - ETA: 4s - loss: 0.010 - ETA: 4s - loss: 0.010 - ETA: 3s - loss: 0.012 - ETA: 3s - loss: 0.012 - ETA: 3s - loss: 0.012 - ETA: 3s - loss: 0.012 - ETA: 3s - loss: 0.011 - ETA: 3s - loss: 0.012 - ETA: 2s - loss: 0.012 - ETA: 2s - loss: 0.012 - ETA: 2s - loss: 0.013 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.014 - ETA: 2s - loss: 0.015 - ETA: 2s - loss: 0.015 - ETA: 1s - loss: 0.015 - ETA: 1s - loss: 0.015 - ETA: 1s - loss: 0.016 - ETA: 1s - loss: 0.016 - ETA: 1s - loss: 0.016 - ETA: 1s - loss: 0.017 - ETA: 0s - loss: 0.017 - ETA: 0s - loss: 0.017 - ETA: 0s - loss: 0.018 - ETA: 0s - loss: 0.018 - ETA: 0s - loss: 0.017 - ETA: 0s - loss: 0.017 - ETA: 0s - loss: 0.017 - 5s 288us/step - loss: 0.0175\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18c8c48a8d0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = os.path.join('models', \"weights-improvement-{epoch:02d}-bigger.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "model_name = 'first_lstm'\n",
    "model_folder = os.path.join('tensorlogs', model_name + \"-logs/\")\n",
    "\n",
    "if not os.path.isdir(model_folder):\n",
    "    n_logs = 0\n",
    "else:\n",
    "    n_logs = len(os.listdir(model_folder))\n",
    "    \n",
    "tensorboard_logs = os.path.join(model_folder, \"%inth_run\"%n_logs)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=tensorboard_logs, write_graph=False)\n",
    "callbacks = [checkpoint, tensorboard_callback]\n",
    "\n",
    "model = make_model((trainX.shape[1], trainX.shape[2]), trainY.shape[-1])\n",
    "\n",
    "model.fit(trainX, trainY, epochs=50, batch_size=512, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict_classes(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9979173897952099"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output == testY.argmax(axis=1)).sum()/len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2830,    21,     1,     0,     0],\n",
       "       [    1, 13099,     1,     8,     3],\n",
       "       [    0,     1,   637,     0,     0],\n",
       "       [    0,     0,     0,   452,     0],\n",
       "       [    0,     0,     0,     0,   232]], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(testY.argmax(axis=1), output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "channel = channels[1]\n",
    "plt.plot(df_healthy.iloc[3][channel][0:window_size])\n",
    "plt.plot(df_myo.iloc[4][channel][0:window_size])\n",
    "plt.plot(df_dys.iloc[2][channel][0:window_size])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "record.label = comments_to_dict(record.comments)['Reason for admission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Myocardial infarction'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acute infarction (localization)': ' infero-latera',\n",
       " 'Additional diagnoses': ' Diabetes mellitus',\n",
       " 'Additional medication': ' Heparin Isosorbit-Mononitrate ASA Diazepam',\n",
       " 'Admission date': ' 29-Sep-90',\n",
       " 'Aorta (at rest) (syst/diast)': ' 160/64 cmH2O',\n",
       " 'Aorta (at rest) mean': ' 106 cmH2O',\n",
       " 'Cardiac index (at rest)': ' n/a',\n",
       " 'Cardiac index (load)': ' n/a',\n",
       " 'Cardiac output (at rest)': ' n/a',\n",
       " 'Cardiac output (load)': ' n/a',\n",
       " 'Catheterization date': ' 16-Oct-90',\n",
       " 'Chest X-ray': ' Heart size upper limit of norm',\n",
       " 'Diagnose': '',\n",
       " 'Dosage (lytic agent)': ' 30 mg',\n",
       " 'ECG date': ' 18/10/1990',\n",
       " 'Echocardiography': ' n/a',\n",
       " 'Former infarction (localization)': ' no',\n",
       " 'Hemodynamics': '',\n",
       " 'In hospital medication': ' ASA Isosorbit-Mononitrate Ca-antagonist Amiloride+Chlorothiazide Glibenclamide Insulin',\n",
       " 'Infarction date': ' 29-Sep-90',\n",
       " 'Infarction date (acute)': ' 29-Sep-90',\n",
       " 'Left coronary artery stenoses (RCX)': ' No stenoses',\n",
       " 'Left coronary artery stenoses (RIVA)': ' RIVA 70% proximal to ramus diagonalis_2',\n",
       " 'Left ventricular enddiastolic pressure': ' 11 cmH2O',\n",
       " 'Lytic agent': ' Gamma-TPA',\n",
       " 'Medication after discharge': ' ASA Isosorbit-Mononitrate Amiloride+Chlorothiazide Glibenclamide',\n",
       " 'Medication pre admission': ' Isosorbit-Dinitrate Digoxin Glibenclamide',\n",
       " 'Number of coronary vessels involved': ' 1',\n",
       " 'Peripheral blood Pressure (syst/diast)': '  140/80 mmHg',\n",
       " 'Previous infarction (1) date': ' n/a',\n",
       " 'Previous infarction (2) date': ' n/a',\n",
       " 'Pulmonary artery pressure (at rest) (mean)': ' n/a',\n",
       " 'Pulmonary artery pressure (at rest) (syst/diast)': ' n/a',\n",
       " 'Pulmonary artery pressure (laod) (mean)': ' n/a',\n",
       " 'Pulmonary artery pressure (laod) (syst/diast)': ' n/a',\n",
       " 'Pulmonary capillary wedge pressure (at rest)': ' n/a',\n",
       " 'Pulmonary capillary wedge pressure (load)': ' n/a',\n",
       " 'Reason for admission': ' Myocardial infarction',\n",
       " 'Right coronary artery stenoses (RCA)': ' No stenoses',\n",
       " 'Smoker': ' no',\n",
       " 'Start lysis therapy (hh.mm)': ' 19',\n",
       " 'Stroke volume index (at rest)': ' n/a',\n",
       " 'Stroke volume index (load)': ' n/a',\n",
       " 'Therapy': '',\n",
       " 'Ventriculography': ' Akinesia inferior wall',\n",
       " 'age': ' 81',\n",
       " 'sex': ' female'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_to_dict(record.comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading files...\n",
      "Finished downloading files\n"
     ]
    }
   ],
   "source": [
    "io.dl_database(db, 'data', records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
